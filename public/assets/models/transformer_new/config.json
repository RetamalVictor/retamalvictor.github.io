{
  "vocab_size": 16384,
  "dim": 512,
  "n_layers": 8,
  "n_heads": 8,
  "max_seq_len": 2048,
  "architecture": "llama",
  "quant_method": "ternary"
}